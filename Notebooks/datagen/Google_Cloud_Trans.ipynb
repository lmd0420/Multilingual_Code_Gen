{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14094,"status":"ok","timestamp":1697057523508,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"},"user_tz":300},"id":"5X1HCWkFvLBy","outputId":"0369de80-c138-4f15-8e28-b314415d39c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting google-cloud-translate==2.0.1\n","  Downloading google_cloud_translate-2.0.1-py2.py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-api-core[grpc]<2.0.0dev,>=1.15.0 (from google-cloud-translate==2.0.1)\n","  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-translate==2.0.1)\n","  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.60.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (3.20.3)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2.17.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2.31.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.59.0)\n","Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.48.2)\n","Collecting google-auth<3.0dev,>=1.25.0 (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1)\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-core<2.0dev,>=1.1.0->google-cloud-translate==2.0.1) (1.16.0)\n","Collecting cachetools<5.0,>=2.0.0 (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1)\n","  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (0.3.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (67.7.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (4.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2023.7.22)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (0.5.0)\n","Installing collected packages: cachetools, google-auth, google-api-core, google-cloud-core, google-cloud-translate\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 5.3.1\n","    Uninstalling cachetools-5.3.1:\n","      Successfully uninstalled cachetools-5.3.1\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 2.17.3\n","    Uninstalling google-auth-2.17.3:\n","      Successfully uninstalled google-auth-2.17.3\n","  Attempting uninstall: google-api-core\n","    Found existing installation: google-api-core 2.11.1\n","    Uninstalling google-api-core-2.11.1:\n","      Successfully uninstalled google-api-core-2.11.1\n","  Attempting uninstall: google-cloud-core\n","    Found existing installation: google-cloud-core 2.3.3\n","    Uninstalling google-cloud-core-2.3.3:\n","      Successfully uninstalled google-cloud-core-2.3.3\n","  Attempting uninstall: google-cloud-translate\n","    Found existing installation: google-cloud-translate 3.11.3\n","    Uninstalling google-cloud-translate-3.11.3:\n","      Successfully uninstalled google-cloud-translate-3.11.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.35.0 which is incompatible.\n","google-cloud-storage 2.8.0 requires google-cloud-core<3.0dev,>=2.3.0, but you have google-cloud-core 1.7.3 which is incompatible.\n","google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 1.35.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cachetools-4.2.4 google-api-core-1.34.0 google-auth-1.35.0 google-cloud-core-1.7.3 google-cloud-translate-2.0.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install google-cloud-translate==2.0.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13632,"status":"ok","timestamp":1697057654238,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"},"user_tz":300},"id":"dXNV0UDUz5eK","outputId":"a4ed68d3-6fa7-4e6a-9f1d-fd80a415955e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1523,"status":"ok","timestamp":1697058247839,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"},"user_tz":300},"id":"hRnJdQoKpOCA","outputId":"39e8c117-ca4d-4bab-c639-c223b5a10618"},"outputs":[{"name":"stdout","output_type":"stream","text":["File train.en.sanitized.csv saved!\n","File validation.en.sanitized.csv saved!\n","File test.en.sanitized.csv saved!\n","File prompt.en.sanitized.csv saved!\n","All English dataset files have been saved and compressed into english_datasets_csv.zip.\n"]}],"source":["import csv\n","from datasets import load_dataset\n","import zipfile\n","\n","# Load MBPP dataset\n","dataset = load_dataset(\"mbpp\", \"sanitized\")\n","\n","# Splits of the dataset to process\n","splits = [\"train\", \"validation\", \"test\", \"prompt\"]\n","\n","# Save each split to a separate CSV file and then add it to a ZIP file\n","with zipfile.ZipFile(\"english_datasets_sanitized_csv.zip\", \"w\") as zipf:\n","    for split in splits:\n","        # Extract the split data\n","        split_data = dataset[split]\n","\n","        # Save the data to a CSV file\n","        filename = f\"{split}.en.sanitized.csv\"\n","        with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n","            writer = csv.writer(file)\n","\n","            # Writing the headers\n","            headers = split_data.column_names\n","            writer.writerow(headers)\n","\n","            # Writing the data rows\n","            for item in split_data:\n","                row = [item[column] for column in headers]\n","                writer.writerow(row)\n","\n","        # Add CSV to ZIP file\n","        zipf.write(filename)\n","\n","        print(f\"File {filename} saved!\")\n","\n","print(\n","    \"All English dataset files have been saved and compressed into english_datasets_csv.zip.\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11995,"status":"ok","timestamp":1696979264613,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"},"user_tz":300},"id":"dOy7RGIkvXiB","outputId":"e06a6b68-e948-4e92-8307-775bcd73a1b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["File train.zh-cn.csv saved!\n","File validation.zh-cn.csv saved!\n","File test.zh-cn.csv saved!\n","File prompt.zh-cn.csv saved!\n","File train.hi.csv saved!\n","File validation.hi.csv saved!\n","File test.hi.csv saved!\n","File prompt.hi.csv saved!\n","File train.es.csv saved!\n","File validation.es.csv saved!\n","File test.es.csv saved!\n","File prompt.es.csv saved!\n","File train.fr.csv saved!\n","File validation.fr.csv saved!\n","File test.fr.csv saved!\n","File prompt.fr.csv saved!\n","File train.ja.csv saved!\n","File validation.ja.csv saved!\n","File test.ja.csv saved!\n","File prompt.ja.csv saved!\n","File train.ru.csv saved!\n","File validation.ru.csv saved!\n","File test.ru.csv saved!\n","File prompt.ru.csv saved!\n","All files have been saved and compressed into translated_datasets.zip.\n"]}],"source":["# running Translate API\n","import pandas as pd\n","from googleapiclient.discovery import build\n","from datasets import load_dataset\n","import zipfile\n","\n","api_key = \"\"\n","# Initialize the Google Cloud Translate API client\n","service = build(\"translate\", \"v2\", developerKey=api_key)\n","\n","\n","# Languages to translate to\n","languages = [\"zh-cn\", \"hi\", \"es\", \"fr\", \"ja\", \"ru\"]\n","# Load MBPP dataset\n","dataset = load_dataset(\"mbpp\")\n","\n","# Splits of the dataset to process\n","splits = [\"train\", \"validation\", \"test\", \"prompt\"]\n","\n","\n","# Function to translate text using Google Cloud Translate API\n","def translate_text(inputs, lang):\n","    outputs = service.translations().list(source=\"en\", target=lang, q=inputs).execute()\n","    return [output[\"translatedText\"] for output in outputs[\"translations\"]]\n","\n","\n","# Create a ZIP file to store all CSVs\n","with zipfile.ZipFile(\"translated_datasets.zip\", \"w\") as zipf:\n","    for lang in languages:\n","        for split in splits:\n","            # Convert to pandas DataFrame for easier processing\n","            df = pd.DataFrame(dataset[split])\n","\n","            # Translate the text column in batches to avoid exceeding the API's limitations\n","            batch_size = 100  # Adjust as needed based on the API's limitations\n","            batches = [\n","                df[\"text\"][i : i + batch_size]\n","                for i in range(0, len(df[\"text\"]), batch_size)\n","            ]\n","            translated_texts = []\n","            for batch in batches:\n","                translated_texts.extend(translate_text(batch.tolist(), lang))\n","\n","            df[\"text\"] = translated_texts\n","\n","            # Save the translated DataFrame to a CSV file\n","            filename = f\"{split}.{lang}.csv\"\n","            df.to_csv(filename, index=False)\n","\n","            # Add CSV to ZIP file\n","            zipf.write(filename)\n","\n","            print(f\"File {filename} saved!\")\n","\n","print(\"All files have been saved and compressed into translated_datasets.zip.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8621,"status":"ok","timestamp":1697058116488,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"},"user_tz":300},"id":"9JHxE4wtqSJr","outputId":"e612a72b-3ee8-4a38-ba35-78e1d91778a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["All translated dataset files have been saved and compressed into translated_datasets_csv.zip.\n"]}],"source":["import json\n","import csv\n","from googleapiclient.discovery import build\n","from datasets import load_dataset\n","import zipfile\n","\n","# Your Google API key\n","api_key = \"AIzaSyDHwDhVGhRfqfD5Bxu1pvxY3onYQgmwohc\"  # Please replace with your actual Google API Key\n","\n","# Initialize the Google Cloud Translate API client\n","service = build(\"translate\", \"v2\", developerKey=api_key)\n","\n","# Languages to translate to\n","languages = [\"zh-cn\", \"hi\", \"es\", \"fr\", \"ja\", \"ru\"]\n","\n","# Load MBPP dataset\n","dataset = load_dataset(\"mbpp\", \"sanitized\")\n","\n","# Splits of the dataset to process\n","splits = [\"train\", \"validation\", \"test\", \"prompt\"]\n","\n","\n","# Function to translate text using Google Cloud Translate API\n","def translate_text(inputs, lang):\n","    outputs = service.translations().list(source=\"en\", target=lang, q=inputs).execute()\n","    return [output[\"translatedText\"] for output in outputs[\"translations\"]]\n","\n","\n","# Create a ZIP file to store all CSV files\n","with zipfile.ZipFile(\"translated_datasets_sanitized_csv.zip\", \"w\") as zipf:\n","    for lang in languages:\n","        for split in splits:\n","            # Convert to a list of dictionaries for easier processing\n","            data = [item for item in dataset[split]]\n","\n","            # Translate the text column in batches to avoid exceeding the API's limitations\n","            batch_size = 100  # Adjust as needed based on the API's limitations\n","            translated_texts = []\n","            for i in range(0, len(data), batch_size):\n","                batch = data[i : i + batch_size]\n","\n","                # Extracting text from the 'prompt' key\n","                texts = [item[\"prompt\"] for item in batch]\n","                translated_texts.extend(translate_text(texts, lang))\n","\n","            # Update the 'prompt' field with the translated texts\n","            for item, translation in zip(data, translated_texts):\n","                item[\"prompt\"] = translation\n","\n","            # Save the data to a CSV file\n","            filename = f\"{split}.{lang}.sanitized.csv\"\n","            with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n","                writer = csv.writer(file)\n","                writer.writerow(\n","                    [\n","                        \"source_file\",\n","                        \"task_id\",\n","                        \"prompt\",\n","                        \"code\",\n","                        \"test_imports\",\n","                        \"test_list\",\n","                    ]\n","                )  # writing headers\n","\n","                for item in data:\n","                    writer.writerow(\n","                        [\n","                            item[\"source_file\"],\n","                            item[\"task_id\"],\n","                            item[\"prompt\"],\n","                            item[\"code\"],\n","                            item[\"test_imports\"],\n","                            item[\"test_list\"],\n","                        ]\n","                    )\n","\n","            # Add CSV to ZIP file\n","            zipf.write(filename)\n","\n","print(\n","    \"All translated dataset files have been saved and compressed into translated_datasets_csv.zip.\"\n",")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPrGUDPndRIgld4pvi+ugXt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
