{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# test.zh-cn.sanitized.results.csv\n",
        "# test.en.sanitized.results (2).csv"
      ],
      "metadata": {
        "id": "aD5p4Q0Cc6t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import zipfile\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkzrzR4Aki2T",
        "outputId": "0fc82a8d-8663-4fe6-9230-712a6446f5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtRMQR3ZQ8b7",
        "outputId": "010ec66f-7c00-401f-9e2b-0373448a8a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and added cleaned_code_hi.csv to the zip file.\n",
            "Processed and added cleaned_code_zh-cn.csv to the zip file.\n",
            "Processed and added cleaned_code_en.csv to the zip file.\n",
            "Processed and added cleaned_code_es.csv to the zip file.\n",
            "Processed and added cleaned_code_ja.csv to the zip file.\n",
            "Processed and added cleaned_code_ru.csv to the zip file.\n",
            "All cleaned files saved to /content/drive/MyDrive/MultilingualLLMBias/results/results-codegemma7b-instruct-FT-GPT/cleaned_csv_files.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "# The path to the directory containing the CSV files\n",
        "#results-Mistral-7B-Instruct-v0.2-LASER\n",
        "folder_path = '/content/drive/MyDrive/MultilingualLLMBias/results/results-codegemma7b-instruct-FT-GPT'\n",
        "\n",
        "# List of language codes or specific identifiers in your file names\n",
        "languages = ['hi', 'zh-cn', 'en', 'es', 'ja', 'ru']\n",
        "\n",
        "# Regular expression pattern to extract the Python function definition\n",
        "pattern = re.compile(r'(def .*?(return [^\\n]+(?:\\s*(elif|else|except).*?(return [^\\n]+)*)*))', re.DOTALL)\n",
        "\n",
        "# Function to clean extracted Python code\n",
        "def clean_extracted_code(source_code):\n",
        "    if not source_code:\n",
        "        return 'YES'\n",
        "\n",
        "    # Removing ellipsis '...'\n",
        "    cleaned_source_code = source_code.replace('...', '')\n",
        "\n",
        "    # Removing lines that start with '#' or are empty\n",
        "    cleaned_source_code = '\\n'.join([line for line in cleaned_source_code.split('\\n') if not line.strip().startswith('#') and line.strip()])\n",
        "\n",
        "    match = pattern.search(cleaned_source_code)\n",
        "    if not match:\n",
        "        return 'YES'\n",
        "\n",
        "    code = match.group(1).strip()\n",
        "\n",
        "    return code\n",
        "\n",
        "# Create a zip file to store all cleaned CSV files\n",
        "zipfile_name = f'{folder_path}/cleaned_csv_files.zip'\n",
        "zipf = zipfile.ZipFile(zipfile_name, 'w', zipfile.ZIP_DEFLATED)\n",
        "\n",
        "# Processing each CSV file according to the language codes/specific identifiers\n",
        "for lang in languages:\n",
        "    file_path = os.path.join(folder_path, f'test.{lang}.sanitized.results.csv')\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        # Read data from CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Apply the regular expression to extract and clean Python code\n",
        "        df['cleaned_code'] = df['results'].apply(lambda x: clean_extracted_code(x))\n",
        "\n",
        "        # Save the cleaned code to a new CSV file\n",
        "        cleaned_file_name = f'cleaned_code_{lang}.csv'\n",
        "        cleaned_file_path = os.path.join('/content', cleaned_file_name)\n",
        "        df.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "        # Add the cleaned CSV file to the zip file\n",
        "        zipf.write(cleaned_file_path, cleaned_file_name)\n",
        "\n",
        "        print(f\"Processed and added {cleaned_file_name} to the zip file.\")\n",
        "    else:\n",
        "        print(f\"File {file_path} does not exist.\")\n",
        "\n",
        "# Close the zip file\n",
        "zipf.close()\n",
        "print(f\"All cleaned files saved to {zipfile_name}\")\n"
      ]
    }
  ]
}