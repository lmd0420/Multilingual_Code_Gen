{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b536102892548448b297a7344085b23",
            "030e25017ac94899ba074b1e249485e4",
            "d7cad67303bc4514836083b4799ce1cd",
            "da6bb7c85d704198ae5882ea85ea2a0a",
            "c6775c15a89e4fef8d062af102a59f79",
            "a6ae2ed64f444f1d9a56dc9f7008629e",
            "69baee1fe7bc4bb98103553e0c262261",
            "99f4b162596a4b1fa52438344a754b6e",
            "a87455b2058b400c9904147c9055e10b",
            "ca8d3e4c84e743129c79e6116373cddd",
            "0c5563acceb246ceb9173463df791226",
            "12d91f04907f4074acbf714f067fd52b",
            "24b150e894ef40c68bc3578e3cd0b941",
            "a8093efaecac4f7d85bc1e8227b75723"
          ]
        },
        "id": "JwnL4h5Dr2pH",
        "outputId": "027b84e3-b902-4ff5-817d-6fc877590d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mistral-finetune'...\n",
            "remote: Enumerating objects: 449, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 449 (delta 146), reused 109 (delta 101), pack-reused 259 (from 1)\u001b[K\n",
            "Receiving objects: 100% (449/449), 234.50 KiB | 19.54 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n",
            "Collecting fire (from -r /content/mistral-finetune/requirements.txt (line 1))\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 2)) (0.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 3)) (6.0.2)\n",
            "Collecting mistral-common>=1.3.1 (from -r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading mistral_common-1.3.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 5)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 6)) (2.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 7)) (4.66.5)\n",
            "Collecting torch==2.2 (from -r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting triton==2.2 (from -r /content/mistral-finetune/requirements.txt (line 10))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting xformers==0.0.24 (from -r /content/mistral-finetune/requirements.txt (line 11))\n",
            "  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.24->-r /content/mistral-finetune/requirements.txt (line 11)) (1.26.4)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/mistral-finetune/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/mistral-finetune/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->-r /content/mistral-finetune/requirements.txt (line 2)) (0.16)\n",
            "Collecting jsonschema==4.21.1 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pydantic==2.6.1 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.2.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (0.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (0.7.0)\n",
            "Collecting pydantic-core==2.16.2 (from pydantic==2.6.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (71.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4)) (2024.7.4)\n",
            "Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading mistral_common-1.3.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=5636a56d5b8e13de7e4d71883152404b9d96b6cfc2ee7f58a64ea3ac68c74ed7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built fire\n",
            "Installing collected packages: sentencepiece, triton, pydantic-core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, tiktoken, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, jsonschema, torch, mistral-common, xformers\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.20.1\n",
            "    Uninstalling pydantic_core-2.20.1:\n",
            "      Successfully uninstalled pydantic_core-2.20.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.8.2\n",
            "    Uninstalling pydantic-2.8.2:\n",
            "      Successfully uninstalled pydantic-2.8.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.13 requires pydantic>=2.7.0, but you have pydantic 2.6.1 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fire-0.6.0 jsonschema-4.21.1 mistral-common-1.3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pydantic-2.6.1 pydantic-core-2.16.2 sentencepiece-0.2.0 tiktoken-0.7.0 torch-2.2.0 triton-2.2.0 xformers-0.0.24\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b536102892548448b297a7344085b23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Clone the mistral-finetune repo\n",
        "!git clone https://github.com/mistralai/mistral-finetune.git\n",
        "!pip install -r /content/mistral-finetune/requirements.txt\n",
        "!pip install huggingface_hub\n",
        "\n",
        "# Login to Huggingface\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "267a537366c84be7a29b772dc012de8a",
            "23110869416e4aa1b57374887706633c",
            "7bb9d740afc447d3b1f9939bbb571349",
            "e409e17e0e764eadb41facb498af1b8f",
            "667b2818afb742db9023138d1ad40382",
            "7c4f9800956f4a9891e64352ad2c8aad",
            "514fe199dc8244bdbf5281aef2515729",
            "7c32c15aac2041da9885670a854a7832",
            "6e02c603bca24d679cd86394ddfeea31",
            "4e591f84460f41f6ad52696fcccdd80c",
            "dd59898730854b398108e4ac0247f233",
            "35d1681250874f659931653e2a5bb705",
            "e43e1a5df9834ecba68c2e30910fc58c",
            "2b8d2bb1575a4ec0a56855aebdad72bc",
            "4de16509d71c43a08fd1690e5c2b2b8c",
            "d8aca9fe8e384c9f9b439ad2f9d080ea",
            "fc337c3f12b54e878647da7b1f8385fa",
            "8dce1035365e4f0abcb3968179e548a3",
            "7a0444908fd341a1bd0d2c76299ea229",
            "01ebab4f4ea54e2eb1d8d6c87b4109e9",
            "ece68958537546619b3c4dcb1c7f0ab7",
            "4aaa119954e642dbb1b36e1fbe2e9514",
            "025ec57d2f214c7195c88727483cb755",
            "7df55f9282204fb9b31e3d3a0f589c6e",
            "a5c39f519fe640948be2417dcb51ceec",
            "c46b68feaaa84aa2a727370d9bc9ede0",
            "c3eb0090d33b40409bb01b70b0b50423",
            "59411b90a061418e880c50c3797a350d",
            "b2c6215d4e144addb799c20b1895f65a",
            "6264a28b39bb48a0af882b21a9df713e",
            "592d6224cea24f2ab817d862bef8b065",
            "bdb14b87d8c142d1886a3c31842b17d3",
            "9950279be5bb4a77a7ce475a7a3f44bc",
            "01c5bc5cfde94c578eb9bca17bcde6ea",
            "8e95a83b148044878b5e409a8b8d902c",
            "17e1479b40074744a44e49ffb92161e1",
            "ffdf501c96d54c16b096a2dcb3bbc8b2",
            "be8e9671538b40d0bbed57e48798e5b3",
            "c8d9d3cc96d94a86a9cd65548d6a16e2",
            "cfee6024590e452ab8ad26db1863d6cd",
            "acbdd5b948654169bd081bf5683c591d",
            "fedb9f112f5244369bdfa28c810a7b95",
            "09765313b8794d11b09931dea30c2aa4",
            "863337f3a726454693aa0dcff7396546"
          ]
        },
        "id": "mVQfbysBtPhu",
        "outputId": "516bd5af-4b72-4902-f7a7-b22b12080c58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "267a537366c84be7a29b772dc012de8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35d1681250874f659931653e2a5bb705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "consolidated.safetensors:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "025ec57d2f214c7195c88727483cb755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c5bc5cfde94c578eb9bca17bcde6ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "params.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consolidated.safetensors  params.json  tokenizer.model.v3\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "\n",
        "mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
        "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "snapshot_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)\n",
        "\n",
        "!mkdir -p /content/mistral_models\n",
        "!cp -r /root/mistral_models/7B-v0.3 /content/mistral_models\n",
        "!rm -r /root/mistral_models/7B-v0.3\n",
        "\n",
        "# Confirm the files have been downloaded\n",
        "!ls /content/mistral_models/7B-v0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3rwcbm3aMG4",
        "outputId": "e0d4f01e-a75a-4f86-9ba9-3e02e980ee99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRDoOts-UxJ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the JSONL file\n",
        "file_path = '/content/drive/MyDrive/ACL/MultilingualLLMBias/GPT3.5-finetune-data/stacked_combined.jsonl'\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "# Split data into training and evaluation sets\n",
        "df_train = df.sample(frac=0.90, random_state=200)  # 90% for training\n",
        "df_eval = df.drop(df_train.index)                  # 10% for evaluation\n",
        "\n",
        "# save data into .jsonl files\n",
        "df_train.to_json(\"ultrachat_chunk_train.jsonl\", orient=\"records\", lines=True)\n",
        "df_eval.to_json(\"ultrachat_chunk_eval.jsonl\", orient=\"records\", lines=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orG96t_Ir9jy",
        "outputId": "60740ebc-d214-465b-cca8-92f26cab3544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ultrachat_chunk_eval.jsonl  ultrachat_chunk_train.jsonl\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/data\n",
        "\n",
        "# Save the reformatted datasets to the /data directory\n",
        "!mv ultrachat_chunk_train.jsonl /content/data/ultrachat_chunk_train.jsonl\n",
        "!mv ultrachat_chunk_eval.jsonl /content/data/ultrachat_chunk_eval.jsonl\n",
        "\n",
        "# Confirm the files exist\n",
        "!ls /content/data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNsTbFb_sFLZ",
        "outputId": "b3597b5d-e56d-4a5f-998f-b6054fba476c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/mistral-finetune\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Navigate to the mistral-finetune directory\n",
        "%cd /content/mistral-finetune/\n",
        "\n",
        "# Validate and reformat the data\n",
        "!python -m utils.reformat_data /content/data/ultrachat_chunk_train.jsonl\n",
        "!python -m utils.reformat_data /content/data/ultrachat_chunk_eval.jsonl\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5pa0ApZsJTi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "# Define the training configuration\n",
        "config = \"\"\"\n",
        "# data\n",
        "data:\n",
        "  instruct_data: \"/content/data/ultrachat_chunk_train.jsonl\"  # Ensure correct path\n",
        "  data: \"\"  # Optionally fill with pretraining data\n",
        "  eval_instruct_data: \"/content/data/ultrachat_chunk_eval.jsonl\"  # Ensure correct path\n",
        "\n",
        "# model\n",
        "model_id_or_path: \"/content/mistral_models/7B-v0.3\"  # Ensure correct path\n",
        "lora:\n",
        "  rank: 64\n",
        "\n",
        "# optim\n",
        "# tokens per training steps = batch_size x num_GPUs x seq_len\n",
        "# we recommend sequence length of 32768\n",
        "# If you run into memory error, you can try reduce the sequence length\n",
        "seq_len: 8192\n",
        "batch_size: 1\n",
        "num_microbatches: 8\n",
        "max_steps: 100\n",
        "optim:\n",
        "  lr: 1.e-4\n",
        "  weight_decay: 0.1\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 1\n",
        "eval_freq: 100\n",
        "no_eval: False\n",
        "ckpt_freq: 100\n",
        "\n",
        "save_adapters: True  # save only trained LoRA adapters. Set to `False` to merge LoRA adapter into the base model and save full fine-tuned model\n",
        "\n",
        "run_dir: \"/content/test_ultra\"  # Ensure correct path\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to example.yaml\n",
        "with open('example.yaml', 'w') as file:\n",
        "    yaml.dump(yaml.safe_load(config), file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhI1kWLcZ-mu"
      },
      "outputs": [],
      "source": [
        "# Ensure the run_dir has not been created before\n",
        "# only run this when you ran torchrun previously and created the /content/test_ultra file\n",
        "\n",
        "#!rm -r /content/test_ultra\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElmX5nV_td8C",
        "outputId": "832b5370-7973-446e-d752-ba03fd994697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-15 05:01:10.061962: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-15 05:01:10.080284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 05:01:10.101560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 05:01:10.108083: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 05:01:10.123713: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 05:01:11.250791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "args: TrainArgs(data=DataArgs(data='', shuffle=False, instruct_data='/content/data/ultrachat_chunk_train.jsonl', eval_instruct_data='/content/data/ultrachat_chunk_eval.jsonl', instruct=InstructArgs(shuffle=True, dynamic_chunk_fn_call=True)), model_id_or_path='/content/mistral_models/7B-v0.3', run_dir='/content/test_ultra', optim=OptimArgs(lr=0.0001, weight_decay=0.1, pct_start=0.05), seed=0, num_microbatches=8, seq_len=8192, batch_size=1, max_norm=1.0, max_steps=100, log_freq=1, ckpt_freq=100, save_adapters=True, no_ckpt=False, num_ckpt_keep=3, eval_freq=100, no_eval=False, checkpoint=True, world_size=1, wandb=WandbArgs(project=None, offline=False, key=None, run_name=None), mlflow=MLFlowArgs(tracking_uri=None, experiment_name=None), lora=LoraArgs(enable=True, rank=64, dropout=0.0, scaling=2.0))\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - distributed - INFO - torch.cuda.device_count: 1\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - distributed - INFO - local rank: 0\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - train - INFO - Going to init comms...\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - train - INFO - Run dir: /content/test_ultra\n",
            "2024-08-15 05:01:12 (UTC) - 0:00:06 - train - INFO - TrainArgs: {'batch_size': 1,\n",
            " 'checkpoint': True,\n",
            " 'ckpt_freq': 100,\n",
            " 'data': {'data': '',\n",
            "          'eval_instruct_data': '/content/data/ultrachat_chunk_eval.jsonl',\n",
            "          'instruct': {'dynamic_chunk_fn_call': True, 'shuffle': True},\n",
            "          'instruct_data': '/content/data/ultrachat_chunk_train.jsonl',\n",
            "          'shuffle': False},\n",
            " 'eval_freq': 100,\n",
            " 'log_freq': 1,\n",
            " 'lora': {'dropout': 0.0, 'enable': True, 'rank': 64, 'scaling': 2.0},\n",
            " 'max_norm': 1.0,\n",
            " 'max_steps': 100,\n",
            " 'mlflow': {'experiment_name': None, 'tracking_uri': None},\n",
            " 'model_id_or_path': '/content/mistral_models/7B-v0.3',\n",
            " 'no_ckpt': False,\n",
            " 'no_eval': False,\n",
            " 'num_ckpt_keep': 3,\n",
            " 'num_microbatches': 8,\n",
            " 'optim': {'lr': 0.0001, 'pct_start': 0.05, 'weight_decay': 0.1},\n",
            " 'run_dir': '/content/test_ultra',\n",
            " 'save_adapters': True,\n",
            " 'seed': 0,\n",
            " 'seq_len': 8192,\n",
            " 'wandb': {'key': None, 'offline': False, 'project': None, 'run_name': None},\n",
            " 'world_size': 1}\n",
            "2024-08-15 05:01:13 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Reloading model from /content/mistral_models/7B-v0.3/consolidated.safetensors ...\n",
            "2024-08-15 05:01:13 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...\n",
            "2024-08-15 05:01:13 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Loaded model on cpu!\n",
            "2024-08-15 05:01:13 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Initializing lora layers ...\n",
            "2024-08-15 05:01:14 (UTC) - 0:00:07 - finetune.wrapped_model - INFO - Finished initialization!\n",
            "2024-08-15 05:01:14 (UTC) - 0:00:07 - finetune.wrapped_model - INFO - Sharding model over 1 GPUs ...\n",
            "2024-08-15 05:01:18 (UTC) - 0:00:12 - finetune.wrapped_model - INFO - Model sharded!\n",
            "2024-08-15 05:01:18 (UTC) - 0:00:12 - finetune.wrapped_model - INFO - 167,772,160 out of 7,415,795,712 parameters are finetuned (2.26%).\n",
            "2024-08-15 05:01:19 (UTC) - 0:00:12 - dataset - INFO - Loading /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:01:19 (UTC) - 0:00:13 - dataset - INFO - /content/data/ultrachat_chunk_train.jsonl loaded and tokenized.\n",
            "2024-08-15 05:01:19 (UTC) - 0:00:13 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:01:38 (UTC) - 0:00:31 - train - INFO - step: 000001 - done (%): 1.0 - loss: 1.134 - lr: 4.0e-06 - peak_alloc_mem (GB): 21.0 - alloc_mem (GB): 17.1 - words_per_second: 3469.6 - avg_words_per_second: 3469.6 - ETA: >2024-08-15 05:32:48\n",
            "2024-08-15 05:01:42 (UTC) - 0:00:36 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:01:55 (UTC) - 0:00:49 - train - INFO - step: 000002 - done (%): 2.0 - loss: 1.077 - lr: 1.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3695.0 - avg_words_per_second: 3578.7 - ETA: >2024-08-15 05:31:50\n",
            "2024-08-15 05:02:04 (UTC) - 0:00:58 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:02:13 (UTC) - 0:01:07 - train - INFO - step: 000003 - done (%): 3.0 - loss: 0.308 - lr: 5.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3726.4 - avg_words_per_second: 3626.6 - ETA: >2024-08-15 05:31:26\n",
            "2024-08-15 05:02:26 (UTC) - 0:01:20 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:02:31 (UTC) - 0:01:24 - train - INFO - step: 000004 - done (%): 4.0 - loss: 1.122 - lr: 8.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3709.8 - avg_words_per_second: 3647.1 - ETA: >2024-08-15 05:31:16\n",
            "2024-08-15 05:02:48 (UTC) - 0:01:42 - train - INFO - step: 000005 - done (%): 5.0 - loss: 0.269 - lr: 1.0e-04 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3722.8 - avg_words_per_second: 3662.0 - ETA: >2024-08-15 05:31:08\n",
            "2024-08-15 05:02:50 (UTC) - 0:01:44 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:03:06 (UTC) - 0:01:59 - train - INFO - step: 000006 - done (%): 6.0 - loss: 0.191 - lr: 1.0e-04 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.2 - avg_words_per_second: 3671.2 - ETA: >2024-08-15 05:31:04\n",
            "2024-08-15 05:03:12 (UTC) - 0:02:06 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:03:24 (UTC) - 0:02:17 - train - INFO - step: 000007 - done (%): 7.0 - loss: 0.154 - lr: 1.0e-04 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3685.0 - avg_words_per_second: 3673.2 - ETA: >2024-08-15 05:31:03\n",
            "2024-08-15 05:03:35 (UTC) - 0:02:28 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:03:41 (UTC) - 0:02:35 - train - INFO - step: 000008 - done (%): 8.0 - loss: 0.104 - lr: 1.0e-04 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3720.7 - avg_words_per_second: 3679.1 - ETA: >2024-08-15 05:31:00\n",
            "2024-08-15 05:03:57 (UTC) - 0:02:50 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:03:59 (UTC) - 0:02:53 - train - INFO - step: 000009 - done (%): 9.0 - loss: 0.054 - lr: 1.0e-04 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3693.1 - avg_words_per_second: 3680.6 - ETA: >2024-08-15 05:30:59\n",
            "2024-08-15 05:04:17 (UTC) - 0:03:10 - train - INFO - step: 000010 - done (%): 10.0 - loss: 0.040 - lr: 9.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3703.8 - avg_words_per_second: 3682.9 - ETA: >2024-08-15 05:30:58\n",
            "2024-08-15 05:04:21 (UTC) - 0:03:15 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:04:34 (UTC) - 0:03:28 - train - INFO - step: 000011 - done (%): 11.0 - loss: 0.046 - lr: 9.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3714.8 - avg_words_per_second: 3685.8 - ETA: >2024-08-15 05:30:57\n",
            "2024-08-15 05:04:43 (UTC) - 0:03:37 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:04:52 (UTC) - 0:03:46 - train - INFO - step: 000012 - done (%): 12.0 - loss: 0.036 - lr: 9.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.9 - avg_words_per_second: 3688.3 - ETA: >2024-08-15 05:30:56\n",
            "2024-08-15 05:05:05 (UTC) - 0:03:59 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:05:10 (UTC) - 0:04:03 - train - INFO - step: 000013 - done (%): 13.0 - loss: 0.024 - lr: 9.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3681.7 - avg_words_per_second: 3687.8 - ETA: >2024-08-15 05:30:56\n",
            "2024-08-15 05:05:28 (UTC) - 0:04:21 - train - INFO - step: 000014 - done (%): 14.0 - loss: 0.022 - lr: 9.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3690.6 - avg_words_per_second: 3688.0 - ETA: >2024-08-15 05:30:56\n",
            "2024-08-15 05:05:28 (UTC) - 0:04:21 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:05:45 (UTC) - 0:04:39 - train - INFO - step: 000015 - done (%): 15.0 - loss: 0.015 - lr: 9.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3713.6 - avg_words_per_second: 3689.7 - ETA: >2024-08-15 05:30:55\n",
            "2024-08-15 05:05:52 (UTC) - 0:04:45 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:06:03 (UTC) - 0:04:56 - train - INFO - step: 000016 - done (%): 16.0 - loss: 0.015 - lr: 9.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3701.6 - avg_words_per_second: 3690.4 - ETA: >2024-08-15 05:30:55\n",
            "2024-08-15 05:06:14 (UTC) - 0:05:08 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:06:21 (UTC) - 0:05:14 - train - INFO - step: 000017 - done (%): 17.0 - loss: 0.012 - lr: 9.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3690.1 - avg_words_per_second: 3690.4 - ETA: >2024-08-15 05:30:55\n",
            "2024-08-15 05:06:36 (UTC) - 0:05:30 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:06:38 (UTC) - 0:05:32 - train - INFO - step: 000018 - done (%): 18.0 - loss: 0.013 - lr: 9.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3696.6 - avg_words_per_second: 3690.7 - ETA: >2024-08-15 05:30:54\n",
            "2024-08-15 05:06:56 (UTC) - 0:05:50 - train - INFO - step: 000019 - done (%): 19.0 - loss: 0.013 - lr: 9.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.5 - avg_words_per_second: 3692.0 - ETA: >2024-08-15 05:30:54\n",
            "2024-08-15 05:06:58 (UTC) - 0:05:52 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:07:14 (UTC) - 0:06:07 - train - INFO - step: 000020 - done (%): 20.0 - loss: 0.009 - lr: 9.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3707.5 - avg_words_per_second: 3692.8 - ETA: >2024-08-15 05:30:53\n",
            "2024-08-15 05:07:23 (UTC) - 0:06:16 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:07:31 (UTC) - 0:06:25 - train - INFO - step: 000021 - done (%): 21.0 - loss: 0.009 - lr: 9.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.9 - avg_words_per_second: 3693.9 - ETA: >2024-08-15 05:30:53\n",
            "2024-08-15 05:07:45 (UTC) - 0:06:38 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:07:49 (UTC) - 0:06:43 - train - INFO - step: 000022 - done (%): 22.0 - loss: 0.010 - lr: 9.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.2 - avg_words_per_second: 3694.9 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:08:07 (UTC) - 0:07:00 - train - INFO - step: 000023 - done (%): 23.0 - loss: 0.009 - lr: 9.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3688.7 - avg_words_per_second: 3694.6 - ETA: >2024-08-15 05:30:53\n",
            "2024-08-15 05:08:07 (UTC) - 0:07:00 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:08:24 (UTC) - 0:07:18 - train - INFO - step: 000024 - done (%): 24.0 - loss: 0.006 - lr: 9.0e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3702.2 - avg_words_per_second: 3694.9 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:08:31 (UTC) - 0:07:25 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:08:42 (UTC) - 0:07:36 - train - INFO - step: 000025 - done (%): 25.0 - loss: 0.009 - lr: 8.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.5 - avg_words_per_second: 3695.8 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:08:53 (UTC) - 0:07:47 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:09:00 (UTC) - 0:07:53 - train - INFO - step: 000026 - done (%): 26.0 - loss: 0.007 - lr: 8.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.0 - avg_words_per_second: 3696.5 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:09:15 (UTC) - 0:08:09 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:09:18 (UTC) - 0:08:11 - train - INFO - step: 000027 - done (%): 27.0 - loss: 0.007 - lr: 8.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3682.5 - avg_words_per_second: 3696.0 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:09:35 (UTC) - 0:08:29 - train - INFO - step: 000028 - done (%): 28.0 - loss: 0.006 - lr: 8.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3688.3 - avg_words_per_second: 3695.7 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:09:38 (UTC) - 0:08:31 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:09:53 (UTC) - 0:08:47 - train - INFO - step: 000029 - done (%): 29.0 - loss: 0.008 - lr: 8.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.1 - avg_words_per_second: 3696.4 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:10:00 (UTC) - 0:08:53 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:10:11 (UTC) - 0:09:04 - train - INFO - step: 000030 - done (%): 30.0 - loss: 0.005 - lr: 8.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3701.7 - avg_words_per_second: 3696.6 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:10:24 (UTC) - 0:09:18 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:10:28 (UTC) - 0:09:22 - train - INFO - step: 000031 - done (%): 31.0 - loss: 0.005 - lr: 8.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3691.3 - avg_words_per_second: 3696.4 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:10:46 (UTC) - 0:09:40 - train - INFO - step: 000032 - done (%): 32.0 - loss: 0.006 - lr: 8.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3699.4 - avg_words_per_second: 3696.5 - ETA: >2024-08-15 05:30:52\n",
            "2024-08-15 05:10:46 (UTC) - 0:09:40 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:11:04 (UTC) - 0:09:57 - train - INFO - step: 000033 - done (%): 33.0 - loss: 0.005 - lr: 8.0e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.6 - avg_words_per_second: 3697.1 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:11:08 (UTC) - 0:10:02 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:11:21 (UTC) - 0:10:15 - train - INFO - step: 000034 - done (%): 34.0 - loss: 0.008 - lr: 7.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3707.2 - avg_words_per_second: 3697.4 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:11:32 (UTC) - 0:10:26 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:11:39 (UTC) - 0:10:33 - train - INFO - step: 000035 - done (%): 35.0 - loss: 0.005 - lr: 7.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.3 - avg_words_per_second: 3698.0 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:11:54 (UTC) - 0:10:48 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:11:57 (UTC) - 0:10:50 - train - INFO - step: 000036 - done (%): 36.0 - loss: 0.004 - lr: 7.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.5 - avg_words_per_second: 3698.5 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:12:14 (UTC) - 0:11:08 - train - INFO - step: 000037 - done (%): 37.0 - loss: 0.006 - lr: 7.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3691.9 - avg_words_per_second: 3698.3 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:12:17 (UTC) - 0:11:10 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:12:32 (UTC) - 0:11:26 - train - INFO - step: 000038 - done (%): 38.0 - loss: 0.005 - lr: 7.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3700.6 - avg_words_per_second: 3698.4 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:12:39 (UTC) - 0:11:32 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:12:50 (UTC) - 0:11:43 - train - INFO - step: 000039 - done (%): 39.0 - loss: 0.004 - lr: 7.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3714.8 - avg_words_per_second: 3698.8 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:13:03 (UTC) - 0:11:57 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:13:07 (UTC) - 0:12:01 - train - INFO - step: 000040 - done (%): 40.0 - loss: 0.005 - lr: 7.0e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.8 - avg_words_per_second: 3699.2 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:13:25 (UTC) - 0:12:19 - train - INFO - step: 000041 - done (%): 41.0 - loss: 0.005 - lr: 6.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3684.6 - avg_words_per_second: 3698.9 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:13:25 (UTC) - 0:12:19 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:13:43 (UTC) - 0:12:37 - train - INFO - step: 000042 - done (%): 42.0 - loss: 0.004 - lr: 6.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3695.5 - avg_words_per_second: 3698.8 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:13:47 (UTC) - 0:12:41 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:14:01 (UTC) - 0:12:54 - train - INFO - step: 000043 - done (%): 43.0 - loss: 0.005 - lr: 6.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.8 - avg_words_per_second: 3699.2 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:14:09 (UTC) - 0:13:03 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:14:18 (UTC) - 0:13:12 - train - INFO - step: 000044 - done (%): 44.0 - loss: 0.004 - lr: 6.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3702.7 - avg_words_per_second: 3699.3 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:14:34 (UTC) - 0:13:27 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:14:36 (UTC) - 0:13:30 - train - INFO - step: 000045 - done (%): 45.0 - loss: 0.004 - lr: 6.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3691.0 - avg_words_per_second: 3699.1 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:14:54 (UTC) - 0:13:47 - train - INFO - step: 000046 - done (%): 46.0 - loss: 0.003 - lr: 6.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3696.6 - avg_words_per_second: 3699.0 - ETA: >2024-08-15 05:30:51\n",
            "2024-08-15 05:14:56 (UTC) - 0:13:50 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:15:11 (UTC) - 0:14:05 - train - INFO - step: 000047 - done (%): 47.0 - loss: 0.004 - lr: 5.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.1 - avg_words_per_second: 3699.4 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:15:18 (UTC) - 0:14:12 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:15:29 (UTC) - 0:14:23 - train - INFO - step: 000048 - done (%): 48.0 - loss: 0.003 - lr: 5.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3707.9 - avg_words_per_second: 3699.6 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:15:40 (UTC) - 0:14:34 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:15:47 (UTC) - 0:14:40 - train - INFO - step: 000049 - done (%): 49.0 - loss: 0.002 - lr: 5.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.1 - avg_words_per_second: 3699.9 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:16:04 (UTC) - 0:14:58 - train - INFO - step: 000050 - done (%): 50.0 - loss: 0.004 - lr: 5.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.0 - avg_words_per_second: 3700.3 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:16:04 (UTC) - 0:14:58 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:16:22 (UTC) - 0:15:16 - train - INFO - step: 000051 - done (%): 51.0 - loss: 0.005 - lr: 5.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3693.4 - avg_words_per_second: 3700.1 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:16:27 (UTC) - 0:15:20 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:16:40 (UTC) - 0:15:33 - train - INFO - step: 000052 - done (%): 52.0 - loss: 0.005 - lr: 5.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3708.2 - avg_words_per_second: 3700.3 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:16:49 (UTC) - 0:15:42 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:16:57 (UTC) - 0:15:51 - train - INFO - step: 000053 - done (%): 53.0 - loss: 0.004 - lr: 4.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.9 - avg_words_per_second: 3700.6 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:17:11 (UTC) - 0:16:04 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:17:15 (UTC) - 0:16:09 - train - INFO - step: 000054 - done (%): 54.0 - loss: 0.005 - lr: 4.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.8 - avg_words_per_second: 3700.9 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:17:33 (UTC) - 0:16:26 - train - INFO - step: 000055 - done (%): 55.0 - loss: 0.003 - lr: 4.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3685.0 - avg_words_per_second: 3700.6 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:17:35 (UTC) - 0:16:29 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:17:51 (UTC) - 0:16:44 - train - INFO - step: 000056 - done (%): 56.0 - loss: 0.004 - lr: 4.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3701.2 - avg_words_per_second: 3700.7 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:17:57 (UTC) - 0:16:51 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:18:08 (UTC) - 0:17:02 - train - INFO - step: 000057 - done (%): 57.0 - loss: 0.003 - lr: 4.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.7 - avg_words_per_second: 3701.0 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:18:19 (UTC) - 0:17:13 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:18:26 (UTC) - 0:17:19 - train - INFO - step: 000058 - done (%): 58.0 - loss: 0.004 - lr: 4.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3700.6 - avg_words_per_second: 3701.0 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:18:41 (UTC) - 0:17:35 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:18:44 (UTC) - 0:17:37 - train - INFO - step: 000059 - done (%): 59.0 - loss: 0.003 - lr: 3.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3682.4 - avg_words_per_second: 3700.6 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:19:01 (UTC) - 0:17:55 - train - INFO - step: 000060 - done (%): 60.0 - loss: 0.005 - lr: 3.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3699.7 - avg_words_per_second: 3700.6 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:19:06 (UTC) - 0:17:59 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:19:19 (UTC) - 0:18:13 - train - INFO - step: 000061 - done (%): 61.0 - loss: 0.004 - lr: 3.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.8 - avg_words_per_second: 3700.9 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:19:28 (UTC) - 0:18:21 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:19:37 (UTC) - 0:18:30 - train - INFO - step: 000062 - done (%): 62.0 - loss: 0.003 - lr: 3.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3704.0 - avg_words_per_second: 3701.0 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:19:50 (UTC) - 0:18:44 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:19:54 (UTC) - 0:18:48 - train - INFO - step: 000063 - done (%): 63.0 - loss: 0.004 - lr: 3.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.8 - avg_words_per_second: 3701.2 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:20:12 (UTC) - 0:19:06 - train - INFO - step: 000064 - done (%): 64.0 - loss: 0.004 - lr: 3.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.3 - avg_words_per_second: 3701.5 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:20:14 (UTC) - 0:19:08 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:20:30 (UTC) - 0:19:23 - train - INFO - step: 000065 - done (%): 65.0 - loss: 0.004 - lr: 3.0e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3692.3 - avg_words_per_second: 3701.3 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:20:36 (UTC) - 0:19:30 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:20:47 (UTC) - 0:19:41 - train - INFO - step: 000066 - done (%): 66.0 - loss: 0.003 - lr: 2.8e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3705.7 - avg_words_per_second: 3701.4 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:20:58 (UTC) - 0:19:52 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:21:05 (UTC) - 0:19:59 - train - INFO - step: 000067 - done (%): 67.0 - loss: 0.004 - lr: 2.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.7 - avg_words_per_second: 3701.7 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:21:20 (UTC) - 0:20:14 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:21:23 (UTC) - 0:20:16 - train - INFO - step: 000068 - done (%): 68.0 - loss: 0.003 - lr: 2.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3719.1 - avg_words_per_second: 3701.9 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:21:40 (UTC) - 0:20:34 - train - INFO - step: 000069 - done (%): 69.0 - loss: 0.004 - lr: 2.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3685.0 - avg_words_per_second: 3701.7 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:21:45 (UTC) - 0:20:38 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:21:58 (UTC) - 0:20:52 - train - INFO - step: 000070 - done (%): 70.0 - loss: 0.004 - lr: 2.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3697.1 - avg_words_per_second: 3701.6 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:22:07 (UTC) - 0:21:01 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:22:16 (UTC) - 0:21:09 - train - INFO - step: 000071 - done (%): 71.0 - loss: 0.005 - lr: 2.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3714.8 - avg_words_per_second: 3701.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:22:29 (UTC) - 0:21:23 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:22:34 (UTC) - 0:21:27 - train - INFO - step: 000072 - done (%): 72.0 - loss: 0.004 - lr: 2.0e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3703.9 - avg_words_per_second: 3701.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:22:51 (UTC) - 0:21:45 - train - INFO - step: 000073 - done (%): 73.0 - loss: 0.003 - lr: 1.9e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3689.8 - avg_words_per_second: 3701.7 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:22:51 (UTC) - 0:21:45 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:23:09 (UTC) - 0:22:03 - train - INFO - step: 000074 - done (%): 74.0 - loss: 0.004 - lr: 1.7e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3699.1 - avg_words_per_second: 3701.6 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:23:16 (UTC) - 0:22:09 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:23:27 (UTC) - 0:22:20 - train - INFO - step: 000075 - done (%): 75.0 - loss: 0.003 - lr: 1.6e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.5 - avg_words_per_second: 3701.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:23:38 (UTC) - 0:22:31 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:23:44 (UTC) - 0:22:38 - train - INFO - step: 000076 - done (%): 76.0 - loss: 0.003 - lr: 1.5e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3708.6 - avg_words_per_second: 3701.9 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:24:00 (UTC) - 0:22:53 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:24:02 (UTC) - 0:22:56 - train - INFO - step: 000077 - done (%): 77.0 - loss: 0.004 - lr: 1.4e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.8 - avg_words_per_second: 3702.1 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:24:20 (UTC) - 0:23:13 - train - INFO - step: 000078 - done (%): 78.0 - loss: 0.004 - lr: 1.3e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.9 - avg_words_per_second: 3702.3 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:24:22 (UTC) - 0:23:15 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:24:37 (UTC) - 0:23:31 - train - INFO - step: 000079 - done (%): 79.0 - loss: 0.005 - lr: 1.2e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3693.5 - avg_words_per_second: 3702.2 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:24:46 (UTC) - 0:23:40 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:24:55 (UTC) - 0:23:49 - train - INFO - step: 000080 - done (%): 80.0 - loss: 0.003 - lr: 1.1e-05 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3702.3 - avg_words_per_second: 3702.2 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:25:08 (UTC) - 0:24:02 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:25:13 (UTC) - 0:24:06 - train - INFO - step: 000081 - done (%): 81.0 - loss: 0.004 - lr: 9.5e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.5 - avg_words_per_second: 3702.4 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:25:30 (UTC) - 0:24:24 - train - INFO - step: 000082 - done (%): 82.0 - loss: 0.004 - lr: 8.6e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.5 - avg_words_per_second: 3702.6 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:25:30 (UTC) - 0:24:24 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:25:48 (UTC) - 0:24:42 - train - INFO - step: 000083 - done (%): 83.0 - loss: 0.003 - lr: 7.7e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3686.0 - avg_words_per_second: 3702.4 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:25:52 (UTC) - 0:24:46 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:26:06 (UTC) - 0:24:59 - train - INFO - step: 000084 - done (%): 84.0 - loss: 0.003 - lr: 6.8e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3696.0 - avg_words_per_second: 3702.3 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:26:17 (UTC) - 0:25:10 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:26:23 (UTC) - 0:25:17 - train - INFO - step: 000085 - done (%): 85.0 - loss: 0.003 - lr: 6.0e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3718.1 - avg_words_per_second: 3702.5 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:26:39 (UTC) - 0:25:32 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:26:41 (UTC) - 0:25:35 - train - INFO - step: 000086 - done (%): 86.0 - loss: 0.003 - lr: 5.3e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3702.8 - avg_words_per_second: 3702.5 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:26:59 (UTC) - 0:25:52 - train - INFO - step: 000087 - done (%): 87.0 - loss: 0.003 - lr: 4.6e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3692.4 - avg_words_per_second: 3702.4 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:27:01 (UTC) - 0:25:55 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:27:17 (UTC) - 0:26:10 - train - INFO - step: 000088 - done (%): 88.0 - loss: 0.002 - lr: 3.9e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3701.5 - avg_words_per_second: 3702.3 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:27:25 (UTC) - 0:26:19 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:27:34 (UTC) - 0:26:28 - train - INFO - step: 000089 - done (%): 89.0 - loss: 0.003 - lr: 3.3e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.3 - avg_words_per_second: 3702.5 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:27:47 (UTC) - 0:26:41 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:27:52 (UTC) - 0:26:45 - train - INFO - step: 000090 - done (%): 90.0 - loss: 0.003 - lr: 2.7e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3707.3 - avg_words_per_second: 3702.6 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:28:10 (UTC) - 0:27:03 - train - INFO - step: 000091 - done (%): 91.0 - loss: 0.003 - lr: 2.2e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3717.2 - avg_words_per_second: 3702.7 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:28:10 (UTC) - 0:27:03 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:28:27 (UTC) - 0:27:21 - train - INFO - step: 000092 - done (%): 92.0 - loss: 0.003 - lr: 1.7e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.3 - avg_words_per_second: 3702.9 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:28:32 (UTC) - 0:27:25 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:28:45 (UTC) - 0:27:38 - train - INFO - step: 000093 - done (%): 93.0 - loss: 0.004 - lr: 1.3e-06 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3692.5 - avg_words_per_second: 3702.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:28:56 (UTC) - 0:27:50 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:29:03 (UTC) - 0:27:56 - train - INFO - step: 000094 - done (%): 94.0 - loss: 0.002 - lr: 9.8e-07 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3700.2 - avg_words_per_second: 3702.7 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:29:18 (UTC) - 0:28:12 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:29:20 (UTC) - 0:28:14 - train - INFO - step: 000095 - done (%): 95.0 - loss: 0.003 - lr: 6.8e-07 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3716.8 - avg_words_per_second: 3702.9 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:29:38 (UTC) - 0:28:31 - train - INFO - step: 000096 - done (%): 96.0 - loss: 0.003 - lr: 4.4e-07 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3715.7 - avg_words_per_second: 3703.0 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:29:40 (UTC) - 0:28:34 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:29:56 (UTC) - 0:28:49 - train - INFO - step: 000097 - done (%): 97.0 - loss: 0.003 - lr: 2.5e-07 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3685.7 - avg_words_per_second: 3702.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:30:02 (UTC) - 0:28:56 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:30:13 (UTC) - 0:29:07 - train - INFO - step: 000098 - done (%): 98.0 - loss: 0.003 - lr: 1.1e-07 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3694.9 - avg_words_per_second: 3702.8 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:30:27 (UTC) - 0:29:20 - dataset - INFO - Shuffling /content/data/ultrachat_chunk_train.jsonl ...\n",
            "2024-08-15 05:30:31 (UTC) - 0:29:25 - train - INFO - step: 000099 - done (%): 99.0 - loss: 0.002 - lr: 2.8e-08 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3714.9 - avg_words_per_second: 3702.9 - ETA: >2024-08-15 05:30:49\n",
            "2024-08-15 05:30:49 (UTC) - 0:29:42 - eval - INFO - Start eval...\n",
            "2024-08-15 05:30:50 (UTC) - 0:29:44 - eval - INFO - Eval finished!\n",
            "2024-08-15 05:30:50 (UTC) - 0:29:44 - train - INFO - step: 000100 - eval_perplexity: 1.023 - eval_loss: 0.032 - train_loss: 0.004\n",
            "2024-08-15 05:30:50 (UTC) - 0:29:44 - train - INFO - step: 000100 - done (%): 100.0 - loss: 0.004 - lr: 4.0e-10 - peak_alloc_mem (GB): 22.2 - alloc_mem (GB): 17.1 - words_per_second: 3411.7 - avg_words_per_second: 3699.7 - ETA: >2024-08-15 05:30:50\n",
            "2024-08-15 05:30:50 (UTC) - 0:29:44 - checkpointing - INFO - Dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000100/consolidated using tmp name: tmp.consolidated\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - checkpointing - INFO - Done dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000100/consolidated for step: 100\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - checkpointing - INFO - Done deleting checkpoints \n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - checkpointing - INFO - Done!\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - train - INFO - done!\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - utils - INFO - Closing: eval_logger\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - utils - INFO - Closed: eval_logger\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - utils - INFO - Closing: metrics_logger\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - utils - INFO - Closed: metrics_logger\n",
            "2024-08-15 05:30:51 (UTC) - 0:29:45 - train - INFO - Closed everything!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Start training\n",
        "!torchrun --nproc-per-node 1 -m train example.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfDc5jycw89W"
      },
      "outputs": [],
      "source": [
        "# Copy the fine-tuned model to Google Drive\n",
        "!cp -r /content/test_ultra /content/drive/MyDrive/ACL/Mistral-7b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p01s3Yicag5m"
      },
      "source": [
        "#below is an inference example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHiKt6zH6DnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b347ce1-baf2-4568-f5c8-5a16dd560de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_inference\n",
            "  Downloading mistral_inference-1.3.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: fire>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.6.0)\n",
            "Requirement already satisfied: mistral_common<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (1.3.3)\n",
            "Requirement already satisfied: safetensors>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.4.4)\n",
            "Requirement already satisfied: simple-parsing>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.1.5)\n",
            "Requirement already satisfied: xformers>=0.0.24 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.0.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.6.0->mistral_inference) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.6.0->mistral_inference) (2.4.0)\n",
            "Requirement already satisfied: jsonschema==4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (4.21.1)\n",
            "Requirement already satisfied: pydantic==2.6.1 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.6.1)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (0.2.0)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (4.12.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (0.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.16.2)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing>=0.1.5->mistral_inference) (0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers>=0.0.24->mistral_inference) (1.26.4)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from xformers>=0.0.24->mistral_inference) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.6.20)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.3.0)\n",
            "Downloading mistral_inference-1.3.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: mistral_inference\n",
            "Successfully installed mistral_inference-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mistral_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "QXFRIBxW5DUe",
        "outputId": "6c223ffc-2792-42cd-d0a9-4038dca2194e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TokenizerException",
          "evalue": "Unrecognized tokenizer file: /content/mistral_models/tokenizer.model.v3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTokenizerException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6031bb5a690e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMistralTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/mistral_models/tokenizer.model.v3\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# change to extracted tokenizer file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/mistral_models\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# change to extracted model dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/test_ultra/checkpoints/checkpoint_000100/consolidated/lora.safetensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mistral_common/tokens/tokenizers/mistral.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, tokenizer_filename, mode)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentencePieceTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTokenizerException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized tokenizer file: {tokenizer_filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mrequest_normalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructRequestNormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTokenizerException\u001b[0m: Unrecognized tokenizer file: /content/mistral_models/tokenizer.model.v3"
          ]
        }
      ],
      "source": [
        "from mistral_inference.transformer import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
        "\n",
        "\n",
        "tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/tokenizer.model.v3\")  # change to extracted tokenizer file\n",
        "model = Transformer.from_folder(\"/content/mistral_models\")  # change to extracted model dir\n",
        "model.load_lora(\"/content/test_ultra/checkpoints/checkpoint_000100/consolidated/lora.safetensors\")\n",
        "\n",
        "completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\n",
        "\n",
        "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
        "\n",
        "out_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
        "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y_s5wvO53df"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01c5bc5cfde94c578eb9bca17bcde6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e95a83b148044878b5e409a8b8d902c",
              "IPY_MODEL_17e1479b40074744a44e49ffb92161e1",
              "IPY_MODEL_ffdf501c96d54c16b096a2dcb3bbc8b2"
            ],
            "layout": "IPY_MODEL_be8e9671538b40d0bbed57e48798e5b3"
          }
        },
        "01ebab4f4ea54e2eb1d8d6c87b4109e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "025ec57d2f214c7195c88727483cb755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df55f9282204fb9b31e3d3a0f589c6e",
              "IPY_MODEL_a5c39f519fe640948be2417dcb51ceec",
              "IPY_MODEL_c46b68feaaa84aa2a727370d9bc9ede0"
            ],
            "layout": "IPY_MODEL_c3eb0090d33b40409bb01b70b0b50423"
          }
        },
        "030e25017ac94899ba074b1e249485e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69baee1fe7bc4bb98103553e0c262261",
            "placeholder": "​",
            "style": "IPY_MODEL_99f4b162596a4b1fa52438344a754b6e",
            "value": "Token is valid (permission: fineGrained)."
          }
        },
        "09765313b8794d11b09931dea30c2aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5563acceb246ceb9173463df791226": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d91f04907f4074acbf714f067fd52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e1479b40074744a44e49ffb92161e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acbdd5b948654169bd081bf5683c591d",
            "max": 202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fedb9f112f5244369bdfa28c810a7b95",
            "value": 202
          }
        },
        "1b536102892548448b297a7344085b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_030e25017ac94899ba074b1e249485e4",
              "IPY_MODEL_d7cad67303bc4514836083b4799ce1cd",
              "IPY_MODEL_da6bb7c85d704198ae5882ea85ea2a0a",
              "IPY_MODEL_c6775c15a89e4fef8d062af102a59f79"
            ],
            "layout": "IPY_MODEL_a6ae2ed64f444f1d9a56dc9f7008629e"
          }
        },
        "23110869416e4aa1b57374887706633c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4f9800956f4a9891e64352ad2c8aad",
            "placeholder": "​",
            "style": "IPY_MODEL_514fe199dc8244bdbf5281aef2515729",
            "value": "Fetching 3 files: 100%"
          }
        },
        "24b150e894ef40c68bc3578e3cd0b941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267a537366c84be7a29b772dc012de8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23110869416e4aa1b57374887706633c",
              "IPY_MODEL_7bb9d740afc447d3b1f9939bbb571349",
              "IPY_MODEL_e409e17e0e764eadb41facb498af1b8f"
            ],
            "layout": "IPY_MODEL_667b2818afb742db9023138d1ad40382"
          }
        },
        "2b8d2bb1575a4ec0a56855aebdad72bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0444908fd341a1bd0d2c76299ea229",
            "max": 14496078512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01ebab4f4ea54e2eb1d8d6c87b4109e9",
            "value": 14496078512
          }
        },
        "35d1681250874f659931653e2a5bb705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e43e1a5df9834ecba68c2e30910fc58c",
              "IPY_MODEL_2b8d2bb1575a4ec0a56855aebdad72bc",
              "IPY_MODEL_4de16509d71c43a08fd1690e5c2b2b8c"
            ],
            "layout": "IPY_MODEL_d8aca9fe8e384c9f9b439ad2f9d080ea"
          }
        },
        "4aaa119954e642dbb1b36e1fbe2e9514": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4de16509d71c43a08fd1690e5c2b2b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece68958537546619b3c4dcb1c7f0ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_4aaa119954e642dbb1b36e1fbe2e9514",
            "value": " 14.5G/14.5G [00:39&lt;00:00, 342MB/s]"
          }
        },
        "4e591f84460f41f6ad52696fcccdd80c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514fe199dc8244bdbf5281aef2515729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592d6224cea24f2ab817d862bef8b065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59411b90a061418e880c50c3797a350d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6264a28b39bb48a0af882b21a9df713e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667b2818afb742db9023138d1ad40382": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69baee1fe7bc4bb98103553e0c262261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e02c603bca24d679cd86394ddfeea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a0444908fd341a1bd0d2c76299ea229": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb9d740afc447d3b1f9939bbb571349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c32c15aac2041da9885670a854a7832",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e02c603bca24d679cd86394ddfeea31",
            "value": 3
          }
        },
        "7c32c15aac2041da9885670a854a7832": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4f9800956f4a9891e64352ad2c8aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df55f9282204fb9b31e3d3a0f589c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59411b90a061418e880c50c3797a350d",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c6215d4e144addb799c20b1895f65a",
            "value": "tokenizer.model.v3: 100%"
          }
        },
        "863337f3a726454693aa0dcff7396546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dce1035365e4f0abcb3968179e548a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e95a83b148044878b5e409a8b8d902c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d9d3cc96d94a86a9cd65548d6a16e2",
            "placeholder": "​",
            "style": "IPY_MODEL_cfee6024590e452ab8ad26db1863d6cd",
            "value": "params.json: 100%"
          }
        },
        "9950279be5bb4a77a7ce475a7a3f44bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f4b162596a4b1fa52438344a754b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c39f519fe640948be2417dcb51ceec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6264a28b39bb48a0af882b21a9df713e",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592d6224cea24f2ab817d862bef8b065",
            "value": 587404
          }
        },
        "a6ae2ed64f444f1d9a56dc9f7008629e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a8093efaecac4f7d85bc1e8227b75723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a87455b2058b400c9904147c9055e10b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acbdd5b948654169bd081bf5683c591d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c6215d4e144addb799c20b1895f65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb14b87d8c142d1886a3c31842b17d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8e9671538b40d0bbed57e48798e5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3eb0090d33b40409bb01b70b0b50423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46b68feaaa84aa2a727370d9bc9ede0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb14b87d8c142d1886a3c31842b17d3",
            "placeholder": "​",
            "style": "IPY_MODEL_9950279be5bb4a77a7ce475a7a3f44bc",
            "value": " 587k/587k [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "c6775c15a89e4fef8d062af102a59f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b150e894ef40c68bc3578e3cd0b941",
            "placeholder": "​",
            "style": "IPY_MODEL_a8093efaecac4f7d85bc1e8227b75723",
            "value": "Login successful"
          }
        },
        "c8d9d3cc96d94a86a9cd65548d6a16e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8d3e4c84e743129c79e6116373cddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfee6024590e452ab8ad26db1863d6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7cad67303bc4514836083b4799ce1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87455b2058b400c9904147c9055e10b",
            "placeholder": "​",
            "style": "IPY_MODEL_ca8d3e4c84e743129c79e6116373cddd",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "d8aca9fe8e384c9f9b439ad2f9d080ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6bb7c85d704198ae5882ea85ea2a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5563acceb246ceb9173463df791226",
            "placeholder": "​",
            "style": "IPY_MODEL_12d91f04907f4074acbf714f067fd52b",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "dd59898730854b398108e4ac0247f233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e409e17e0e764eadb41facb498af1b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e591f84460f41f6ad52696fcccdd80c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd59898730854b398108e4ac0247f233",
            "value": " 3/3 [00:40&lt;00:00, 40.01s/it]"
          }
        },
        "e43e1a5df9834ecba68c2e30910fc58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc337c3f12b54e878647da7b1f8385fa",
            "placeholder": "​",
            "style": "IPY_MODEL_8dce1035365e4f0abcb3968179e548a3",
            "value": "consolidated.safetensors: 100%"
          }
        },
        "ece68958537546619b3c4dcb1c7f0ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc337c3f12b54e878647da7b1f8385fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedb9f112f5244369bdfa28c810a7b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffdf501c96d54c16b096a2dcb3bbc8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09765313b8794d11b09931dea30c2aa4",
            "placeholder": "​",
            "style": "IPY_MODEL_863337f3a726454693aa0dcff7396546",
            "value": " 202/202 [00:00&lt;00:00, 15.1kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}