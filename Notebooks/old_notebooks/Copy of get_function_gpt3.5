{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DU0Z7PW-UqUXJBlutnMByNcdNSnaxmvp","timestamp":1697510252796}],"authorship_tag":"ABX9TyNEBDymojdAimMLaDE7tRwv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbQFusDf1Kl2","executionInfo":{"status":"ok","timestamp":1697823003711,"user_tz":300,"elapsed":15144,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"}},"outputId":"7d16feaa-6fb1-4726-9e74-9dd143e01665"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"VnVrpC8WxJ8m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697826452855,"user_tz":300,"elapsed":450,"user":{"displayName":"Mingda Li","userId":"10577302496462889642"}},"outputId":"86f72128-a4fb-4d0c-caae-397341cab5d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed and added cleaned_code_hi.csv to the zip file.\n","Processed and added cleaned_code_zh-cn.csv to the zip file.\n","Processed and added cleaned_code_es.csv to the zip file.\n","Processed and added cleaned_code_ja.csv to the zip file.\n","Processed and added cleaned_code_ru.csv to the zip file.\n","Processed and added cleaned_code_en.csv to the zip file.\n","All cleaned files saved to /content/drive/MyDrive/EACL/MultilingualLLMBias/results/results-GPT3.5/cleaned_csv_files.zip\n"]}],"source":["# Import necessary libraries\n","import os\n","import re\n","import pandas as pd\n","import zipfile\n","\n","# The path to the directory containing the CSV files\n","folder_path = '/content/drive/MyDrive/EACL/MultilingualLLMBias/results/results-GPT3.5'  # Change this to the path of your folder with new CSV files\n","\n","# List of language codes or specific identifiers in your file names\n","languages = ['hi', 'zh-cn', 'es', 'ja', 'ru','en']  # Modify as needed\n","\n","# Regular expression patterns\n","pattern = re.compile(r'```python(.*?)```', re.DOTALL)\n","assert_pattern = re.compile(r'^assert.*$', re.MULTILINE)\n","function_pattern = re.compile(r'(def .*?return [^\\n]+)', re.DOTALL)\n","post_function_pattern = re.compile(r'(def .*?return [^\\n]+)', re.DOTALL)\n","\n","# Create a zip file to store all cleaned CSV files\n","zipfile_name = '/content/drive/MyDrive/EACL/MultilingualLLMBias/results/results-GPT3.5/cleaned_csv_files.zip'\n","zipf = zipfile.ZipFile(zipfile_name, 'w', zipfile.ZIP_DEFLATED)\n","\n","def extract_and_clean_code(text):\n","    match = pattern.search(text)\n","    if match:\n","        code = match.group(1).strip()\n","        cleaned_code = assert_pattern.sub('', code).strip()  # Remove lines starting with 'assert'\n","        function_match = post_function_pattern.search(cleaned_code)  # Extract only the function definition\n","        if function_match:\n","            return function_match.group(1).strip()\n","        return cleaned_code\n","\n","    # If no match for the first pattern, try the second pattern\n","    match = function_pattern.search(text)\n","    if match:\n","        return match.group(1).strip()\n","\n","    # If still no match, return 'YES'\n","    return 'YES'\n","\n","# Process each CSV file according to the language codes/specific identifiers\n","for lang in languages:\n","    file_path = os.path.join(folder_path, f'gpt3.5_results.{lang}.sanitized.csv')\n","\n","    if os.path.exists(file_path):\n","        # Read data from CSV file\n","        df = pd.read_csv(file_path)\n","\n","        # Apply the function to extract and clean Python code\n","        df['cleaned_code'] = df['gpt_result'].apply(extract_and_clean_code)\n","        #df['cleaned_code'] = df['gpt_result']\n","        # Save the cleaned code to a new CSV file\n","        cleaned_file_name = f'cleaned_code_{lang}.csv'\n","        cleaned_file_path = os.path.join('/content', cleaned_file_name)\n","        df.to_csv(cleaned_file_path, index=False)\n","\n","        # Add the cleaned CSV file to the zip file\n","        zipf.write(cleaned_file_path, cleaned_file_name)\n","\n","        print(f\"Processed and added {cleaned_file_name} to the zip file.\")\n","    else:\n","        print(f\"File {file_path} does not exist.\")\n","\n","# Close the zip file\n","zipf.close()\n","print(f\"All cleaned files saved to {zipfile_name}\")"]}]}